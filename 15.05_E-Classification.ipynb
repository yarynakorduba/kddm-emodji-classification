{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "import gensim.downloader as api\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Emoji prediction (Classification task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The dataset consists of crawled tweets from Twitter. Every tweet is labeled with a class corresponding to the emoji the user put after the text of the tweet. Your task is to predict the emoji from a given tweet. This exercise represents a typical application of a classification task. As with the regression task, report all your preprocessing steps and mind their importance. The dataset consists of a separate training and testing dataset. Report your performance, including overall accuracy, precision and recall for all classes and the micro and macro average for precision and recall, on the test dataset!\n",
    "\n",
    "#### Hint: The train and test datasets are pickle files (.pkl). Use the function pandas.read_pickle(path) to read the files into a pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>emoji_class</th>\n",
       "      <th>emoji</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lmao. My #Bitmoji is so perfect. Looks and act...</td>\n",
       "      <td>1</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I like to call this the #tandem because we dec...</td>\n",
       "      <td>0</td>\n",
       "      <td>‚ù§</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crab dip French toast! Yum! I Miss Shirley's! ...</td>\n",
       "      <td>0</td>\n",
       "      <td>‚ù§</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Happy Thanksgiving from my family to yours! Ô∏è ...</td>\n",
       "      <td>0</td>\n",
       "      <td>‚ù§</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#familynight Ô∏è @ Soho House West Hollywood \\n</td>\n",
       "      <td>0</td>\n",
       "      <td>‚ù§</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10652</th>\n",
       "      <td>Overshine by the sunlight Ô∏è - Golden gate brid...</td>\n",
       "      <td>6</td>\n",
       "      <td>‚òÄ</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10653</th>\n",
       "      <td>Those one handed interception drills coming in...</td>\n",
       "      <td>3</td>\n",
       "      <td>üî•</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10654</th>\n",
       "      <td>Can I get a for this good looking group? We're...</td>\n",
       "      <td>0</td>\n",
       "      <td>‚ù§</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10655</th>\n",
       "      <td>w/ @user : @user with the shots @ Manhattan, N...</td>\n",
       "      <td>2</td>\n",
       "      <td>üì∏</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10656</th>\n",
       "      <td>Obligatory Wedding Kiss Pic with @user Ô∏èqnhamp...</td>\n",
       "      <td>0</td>\n",
       "      <td>‚ù§</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10657 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweet  emoji_class emoji  \\\n",
       "0      Lmao. My #Bitmoji is so perfect. Looks and act...            1     üòÇ   \n",
       "1      I like to call this the #tandem because we dec...            0     ‚ù§   \n",
       "2      Crab dip French toast! Yum! I Miss Shirley's! ...            0     ‚ù§   \n",
       "3      Happy Thanksgiving from my family to yours! Ô∏è ...            0     ‚ù§   \n",
       "4          #familynight Ô∏è @ Soho House West Hollywood \\n            0     ‚ù§   \n",
       "...                                                  ...          ...   ...   \n",
       "10652  Overshine by the sunlight Ô∏è - Golden gate brid...            6     ‚òÄ   \n",
       "10653  Those one handed interception drills coming in...            3     üî•   \n",
       "10654  Can I get a for this good looking group? We're...            0     ‚ù§   \n",
       "10655  w/ @user : @user with the shots @ Manhattan, N...            2     üì∏   \n",
       "10656  Obligatory Wedding Kiss Pic with @user Ô∏èqnhamp...            0     ‚ù§   \n",
       "\n",
       "      predicted_class  \n",
       "0                None  \n",
       "1                None  \n",
       "2                None  \n",
       "3                None  \n",
       "4                None  \n",
       "...               ...  \n",
       "10652            None  \n",
       "10653            None  \n",
       "10654            None  \n",
       "10655            None  \n",
       "10656            None  \n",
       "\n",
       "[10657 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_pickle(\"./emoji_train.pkl\")      # Shape: (42627, 4)\n",
    "df_test = pd.read_pickle(\"./emoji_test.pkl\")        # (10657, 4)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Classes: 6\n"
     ]
    }
   ],
   "source": [
    "n_classes = df_train['emoji_class'].max()\n",
    "print(\"Number of Classes:\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['tweet'].values              # (42627,)\n",
    "X_test = df_test['tweet'].values                # (10657,)\n",
    "y_train = df_train['emoji_class'].values        # (42627,)\n",
    "y_test = df_test['emoji_class'].values          # (10657,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Array to Torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: torch.Size([42627]) y_test: torch.Size([10657])\n"
     ]
    }
   ],
   "source": [
    "#X_train = torch.from_numpy(X_train)    \tencode the words as some indices similar to the Lang class in the Seq2Seq Tutorial\n",
    "y_train = torch.from_numpy(y_train)         # Shape 1D\n",
    "# X_test = torch.from_numpy(X_test)\n",
    "y_test = torch.from_numpy(y_test)           # Shape 1D \n",
    "print(\"y_train:\", y_train.shape, \"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Word Embeddings and convert string to vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(originalString):\n",
    "  cleanString = originalString.lower() # lowercase\n",
    "  cleanString = re.sub(r'/(<.*?>)|[@]|[^\\w\\d\\n]/g', ' ', cleanString) # replace non-word chars\n",
    "  cleanString = re.sub(r'/(ies|y|ed|ing|s)(\\s|\\b)/g', ' ', cleanString) # stemming of the word endings\n",
    "  cleanString = re.sub(r'/\\s{2,}/g', ' ', cleanString) # replace redundand whitespaces\n",
    "  # cleanString = cleanString.trim() # trim leading and ending whitespaces\n",
    "\n",
    "  return cleanString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = api.load('text8')\n",
    "model = Word2Vec(corpus)\n",
    "model.wv['tree'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove stop words\n",
    "def createCumulativeSentenceEmbedding(accum, word):\n",
    "  if (len(word) == 0):\n",
    "    return accum\n",
    "  if (isinstance(accum, str)):\n",
    "    if (accum in model.wv):\n",
    "      accum = model.wv[accum]\n",
    "    else:\n",
    "      accum = ''\n",
    "\n",
    "  if(word in model.wv):\n",
    "    wordVec = model.wv[word]\n",
    "    if (isinstance(accum, str)):\n",
    "      return wordVec\n",
    "    vSum = accum.copy()\n",
    "    for index in range(1, accum.size):\n",
    "      vSum[index] = accum[index] + wordVec[index]\n",
    "    return vSum\n",
    "  else:\n",
    "    return accum\n",
    "\n",
    "def createEmbeddings(text):\n",
    "  try:\n",
    "    cleanedString = preprocess(text)\n",
    "    words = cleanedString.split(' ')\n",
    "    vectorSum = functools.reduce(lambda accum, word: createCumulativeSentenceEmbedding(accum, word), words)\n",
    "    if (isinstance(vectorSum, str)):\n",
    "      return [0] * 100\n",
    "    vGetAveragedVector = np.vectorize(lambda value: value / len(words))\n",
    "    averagedVector = vGetAveragedVector(vectorSum)\n",
    "    return averagedVector\n",
    "  except Exception as error:\n",
    "    print(\"Error: \", text, error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['tweet'].map(createEmbeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\AppData\\Local\\Temp/ipykernel_29600/269691483.py:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  X_train = torch.Tensor(X_train)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.to_frame()\n",
    "X_train = X_train.values.tolist()\n",
    "X_train = torch.Tensor(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = X_train.squeeze()\n",
    "#y_train = y_train.unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([42627, 1, 100]) <class 'torch.Tensor'> torch.Size([42627]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, type(X_train), y_train.shape, type(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can select between different models, Deep Neural Network, SVM, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input 3 Channels two classes, can be changed \n",
    "class ConvModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvModel, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "                    nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool1d(3, stride=2),\n",
    "                    nn.Conv1d(in_channels=64, out_channels=96, kernel_size=3, padding=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool1d(3, stride=2),\n",
    "                    nn.Conv1d(in_channels=96, out_channels=128, kernel_size=3, padding=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool1d(3, stride=2),\n",
    "                    nn.Conv1d(in_channels=128, out_channels=32, kernel_size=3, padding=1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.MaxPool1d(3, stride=2)\n",
    "                    )       \n",
    "\n",
    "    def forward(self,x):\n",
    "        x= self.conv1(x)\n",
    "        x= x.view(x.size(0), -1)            # Flattening\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guter test \n",
    "class MLP_V2_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(100, 16)\n",
    "        #self.hidden2 = nn.Linear(80, 32)\n",
    "        self.output = nn.Linear(16, 1)\n",
    "        #self.relu = nn.ReLU()\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.hidden(x)\n",
    "        #x = self.sigmoid(x)\n",
    "        #x = self.hidden2(x)\n",
    "        #x = self.relu(x)\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(TinyModel, self).__init__()\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(100, 200)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(200, 1)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose different loss (BCE, MSE, CrossEntropy loss, Choose different schedular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, X_train, train_y, max_epoch):\n",
    "\n",
    "  train_loss = []\n",
    "  train_acc = []\n",
    "  y_target =[]\n",
    "\n",
    "  # Divide the learning rate by 2 at each epoch, as suggested in paper\n",
    "  scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.5, last_epoch=-1)     # Decays the learning rate of each parameter group by gamma every step_size epochs. \n",
    "  #                                                                                   Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler.\n",
    "  #                                                                                   When last_epoch = -1, sets initial lr as lr.\n",
    "  epoch = 0                                                                         # Epochs done so far\n",
    "  stop = False   \n",
    "  \n",
    "  #loss_func=torch.nn.BCELoss()                                                                   # Status to know when to stop\n",
    "  loss_func = nn.CrossEntropyLoss()\n",
    "  #loss_func = nn.SmoothL1Loss()\n",
    "\n",
    "\n",
    "  while epoch < max_epoch and not stop:                   \n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "\n",
    "    optimizer.zero_grad()                                                          # Sets the gradients of all optimized torch.Tensors to zero\n",
    "\n",
    "    yhat = model(X_train)                     # input x and predict based on \n",
    "    #print(yhat.shape, yhat)\n",
    "    #out = out.squeeze()\n",
    "    #train_y = train_y.to(torch.float)\n",
    "    #print(train_y.shape, train_y)\n",
    "    #yhat = yhat.to(torch.float)\n",
    "    #yhat =yhat.double()\n",
    "    loss = loss_func(yhat, train_y)           # must be (1. nn output, 2. target), the target label is NOT one-hotted\n",
    "    #loss = loss.to(torch.float32)\n",
    "    loss.backward()                           # backward pass\n",
    "    optimizer.step()                          # gradient descent; Performs a single optimization step (parameter update)                                                                               \n",
    "      \n",
    "    #Print the statistic\n",
    "    running_loss += loss                                                \n",
    "    #running_acc += loss\n",
    "\n",
    "    epoch_loss = running_loss\n",
    "    epoch_acc = running_acc\n",
    "    print('Epoch {:d} -- Loss: {:.4f} '.format(epoch+1,epoch_loss))\n",
    "    #print('Epoch {:d} -- Loss: {:.4f} Acc: {:.4f}'.format(epoch+1,epoch_loss, epoch_acc))\n",
    "    epoch += 1\n",
    "    scheduler.step()                                                                 # This change the learning rate at each epoch, otherwise the LR would stays at the initial value                                             \n",
    "    train_loss.append(loss)\n",
    "    #train_acc= np.append(train_acc,epoch_acc)\n",
    "    #y_target.append(target_inds)\n",
    "\n",
    "  return train_loss, train_acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -- Loss: 5.0390 \n",
      "Epoch 2 -- Loss: 5.0050 \n",
      "Epoch 3 -- Loss: 4.9723 \n",
      "Epoch 4 -- Loss: 4.9486 \n",
      "Epoch 5 -- Loss: 4.9334 \n",
      "Epoch 6 -- Loss: 4.9243 \n",
      "Epoch 7 -- Loss: 4.9190 \n",
      "Epoch 8 -- Loss: 4.9160 \n",
      "Epoch 9 -- Loss: 4.9144 \n",
      "Epoch 10 -- Loss: 4.9135 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29600/2043975345.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=5e-4) #  L2 regularization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29600/3557326121.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, X_train, train_y, max_epoch)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                                                          \u001b[1;31m# Sets the gradients of all optimized torch.Tensors to zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m                     \u001b[1;31m# input x and predict based on\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;31m#print(yhat.shape, yhat)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m#out = out.squeeze()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\patri\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29600/2205699082.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m            \u001b[1;31m# Flattening\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\patri\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\patri\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\patri\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\patri\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\pooling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m         return F.max_pool1d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[0;32m     89\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m                             self.return_indices)\n",
      "\u001b[1;32mc:\\Users\\patri\\anaconda3\\lib\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    420\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\patri\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_max_pool1d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    651\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m         \u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 653\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = ConvModel()\n",
    "#model = MLP_V2_2()\n",
    "#model = TinyModel()\n",
    "\n",
    "max_epoch = 1000\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=5e-4) #  L2 regularization\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "train_loss, train_acc = train(model, optimizer, X_train, y_train, max_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_x, test_y, test_episode):\n",
    "  target_test =[]\n",
    "  pred_test =[]\n",
    "\n",
    "  running_loss = 0.0\n",
    "  running_acc = 0.0\n",
    "  for episode in tnrange(test_episode):                                                  \n",
    "\n",
    "    ypred = model(X_test)\n",
    "    running_loss += output['loss']\n",
    "    running_acc += output['acc']\n",
    "    target_test.append(target_inds)\n",
    "    pred_test.append(y_hat)\n",
    "    \n",
    "  avg_loss = running_loss / test_episode\n",
    "  avg_acc = running_acc / test_episode\n",
    "  #print('Test results -- Loss: {:.4f} Acc: {:.4f}'.format(avg_loss, avg_acc))\n",
    "  \n",
    "  return avg_loss, avg_acc, y_target, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_episode = 1000\n",
    "\n",
    "test_loss, test_acct, y_target, y_pred =test(model, X_test, y_test, test_episode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"True set of labels in training:\", y_target)\n",
    "print(\"Predicted set of labels in training:\", y_pred)\n",
    "print( \"True set of labels in test:\", y_target_test)\n",
    "print( \"Predicted set of labels in test:\", y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)             # use LaTeX fonts in the plot\n",
    "plt.rc('font', family='serif')\n",
    "sns.set_theme(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss, label='loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss [Anomaly]')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = accuracy_score(y_target_test, y_pred_test)\n",
    "plt.plot(train_acc, label='accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy [Anomaly]')\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_score = accuracy_score(y_target_test, y_pred_test)\n",
    "print(a_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-Score & Precision & Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score( y_target_test,y_pred_test, pos_label=1)\n",
    "precision = precision_score( y_target_test,y_pred_test)\n",
    "recall = recall_score( y_target_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cm(y_target_test, y_pred_test):         \n",
    "    cm = confusion_matrix(y_pred_test, y_target_test)\n",
    "    cm = cm.tolist()\n",
    "    cm_dict = {'class'+str(count): cm[count] for count in range(len(cm))}\n",
    "    return cm, cm_dict\n",
    "\n",
    "\n",
    "cm = confusion_matrix( y_target_test,y_pred_test)\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "categories = ['Negativ(0)','Positiv(1)']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cm, annot=labels, fmt='', cmap=\"icefire_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Accuracy:\", format(test_acc, \".3f\"))\n",
    "print(\" Loss:\", format(test_loss, \".3f\"))\n",
    "print(\" F1 Score: %.3f\" % f1)\n",
    "print(\" Precision :\", format(precision, \".3f\"))\n",
    "print(\" Recall:\", format(recall, \".1f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Train Loss': train_loss,\n",
    "                   'Train Accuracy': train_acc,\n",
    "                   'Test Loss': test_loss,\n",
    "                   'Test Accuracy': test_acc,\n",
    "                   'F1-Score': f1,\n",
    "                   'Precision': precision,\n",
    "                   'Recall': recall,\n",
    "                   })\n",
    "                   \n",
    "df_label = pd.DataFrame({ 'y_pred_test': y_pred_test,\n",
    "                           'y_target_test': y_target_test\n",
    "                    })\n",
    "\n",
    "\n",
    "pd.DataFrame(df).to_csv(\"/Users/PFR1UL/Desktop/.csv\", index = False)\n",
    "pd.DataFrame(df_label).to_csv(\"/Users/PFR1UL/Desktop/.csv\", index = False)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0eb5d0a65b500759bcde1c4c1ad0551eaece71d5bef76353acf57400c52edb49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
